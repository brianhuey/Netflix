#from nmfplus import *
import random
import numpy as np
import scipy.sparse as sp
import math

def predict_with_cluster(user,movie,At,A,cosine_sim=False):
    if ((user >= At.shape[0]) or (movie >= At.shape[1])):
        return(0.0,0.0)
    
    raw = A.getrow(movie)
    movie_neighbors = raw.transpose()
    if cosine_sim:
        mag_movie = math.sqrt(raw.dot(movie_neighbors)[0,0])

    val = 0
    #     print At.shape
    #     print user,movie
    for row_col_index in xrange(At.indptr[user],At.indptr[user+1]):
        rated_movie = At.indices[row_col_index]

        rated_movie_neighbors = A.getrow(rated_movie)

        if cosine_sim:
            mag_rated_movie = math.sqrt(rated_movie_neighbors.dot(rated_movie_neighbors.transpose())[0,0])

        score = rated_movie_neighbors.dot(movie_neighbors)[0,0]/(mag_rated_movie*mag_movie)
        #         print "score", score
        #         print rated_movie,movie
        #         print rated_movie_neighbors
        #         print "movie_neighbors"
        #         print movie_neighbors

        val += score
        #print "val", val
        
    return (val,At.indptr[user+1]-At.indptr[user])

# Helper function for finding ith nonzero entry
# in sparse matrix representation
def find_index(array,val,left=0, right = False):
    if not right:
        right = len(array)
    if right-left <= 1:
        return left
    else:
        mid = (right+left)/2
        if (val >= array[mid]):
            return find_index(array,val,left=mid,right=right)
        else:
            return find_index(array,val,left=left,right=mid)


# Reading the data from the netflix files into matrix
#  - returns the dictionaries for translating between row/col to movie/user
#  - will take dictionary so that one can translate test data to use
#  - same matrix that was formed using training data.
def read_data(filename,movie_ids={},user_ids={},n_movies=0,n_users=0,discard =False):

    f = open(filename)

    row = []
    column = []
    values = []

    for line in f:
        fields = line.strip().split(",")

        movie_id = fields[0]
        user_id = fields[1]

        if discard and ((not movie_id in movie_ids) or (not user_id in user_ids)):
            continue

        if not movie_id in movie_ids:
            movie_ids[movie_id] = n_movies
            n_movies+=1
        if not user_id in user_ids:
            user_ids[user_id] = n_users
            n_users += 1

        row.append(movie_ids[movie_id])
        column.append(user_ids[user_id])
        # values.append(float(fields[2]))
        values.append(1.0)

    f.close()

    print n_movies,n_users

    return((sp.csr_matrix((values,(row,column)),shape=(n_movies,n_users)),
            movie_ids,user_ids,n_movies,n_users))

def inverse_map(the_mapping):
    reverse_mapping = {}
    for key in the_mapping.keys():
        reverse_mapping[the_mapping[key]] = key
    return reverse_mapping

def cluster_prediction(filename,test_filename,dir_prefix="./cluster.", cosine_sim=False):

    outfile = open(dir_prefix+"test.predictions","w")

    (A,movie_ids,user_ids,m_count,u_count) = read_data(filename)

    reverse_user = inverse_map(user_ids)
    reverse_movie = inverse_map(movie_ids)
    At = A.transpose()
    n_samples = 10000
    
    trainA = A
    train_m_count = m_count
    train_u_count = u_count
    At = At.tocsr()

    (A,movie_ids,user_ids,m_count,u_count) = read_data(test_filename,movie_ids,user_ids,m_count,u_count,discard=True)
    
    #outfile2 = open(dir_prefix+"test.predictions2","w")

    print ("Total of %d test ratings" % A.nnz)
    (n,m) = A.shape
    cnt=0

    # print_int = min(A.nnz/10,1000)
    # for row in xrange(n):
    #     for row_col_index in xrange(A.indptr[row],A.indptr[row+1]):
    #         col = A.indices[row_col_index]
    #         elt = A.data[row_col_index]
    #         (val1,val2) = predict_with_cluster(col,row,At,graph)
    #         cnt+=1
    #         if (cnt%print_int== 0):
    #             print "cnt,movie,user,val1", cnt, row,col,val1
    #         print >> outfile, "%s,%s,%0.5f" % (reverse_movie[row],reverse_user[col], val1)

    print_int = 100
    for row in xrange(min(n_samples,A.nnz)):
        i = random.randint(0,A.nnz -1)
        row = find_index(A.indptr,i)            
        col = A.indices[i]
        (val1,deg) = predict_with_cluster(col,row,At,trainA,cosine_sim)
        cnt+=1
        if (cnt%print_int == 0):
            print "cnt,movie,user,deg,val1", cnt, row,col,deg,val1
        print >> outfile, "%s,%s,%0.5f,%0.5f" % (reverse_movie[row],reverse_user[col], val1,deg)
        
    outfile.close()

    # Test on completely random pairs
    print ("Doing random pairs")
    print_int = 100
    outfile = open(dir_prefix + "test.rndpairs.predictions","w")
    for n_pairs in xrange(n_samples):
        row = random.randint(0,n-1)
        col = random.randint(0,m-1)
        (val1,deg) = predict_with_cluster(col,row,At,trainA,cosine_sim)
        cnt+=1
        if (cnt%print_int == 0):
            print "cnt,movie,user,deg,val1", cnt, row,col,deg,val1
        print >> outfile, "%s,%s,%0.5f,%0.5f" % (reverse_movie[row],reverse_user[col], val1,deg)

    outfile.close()

    # Test on difficult distribution that ephasizes non-rated pairs where movies and users
    # are chosen based on rating count.
    print ("Doing random difficult pairs")
    outfile = open(dir_prefix+"test.hard.rndpairs.predictions","w")
    for n_pairs in xrange(n_samples):
        i = random.randint(0,A.nnz -1)
        row = find_index(A.indptr,i)
        j = random.randint(0,A.nnz -1)
        col = A.indices[j]
        if (row > A.shape[0]-1):
            print row, A.shape, "what is going on"
            continue
        if (col > A.shape[1]-1):
            print col, A.shape, "what is going on"
            continue
        (val1,deg) = predict_with_cluster(col,row,At,trainA,cosine_sim)

        if (A[row,col] > 0 or trainA[row,col] > 0):
            continue
        cnt+=1
        if (cnt%print_int == 0):
            print "cnt,movie,user,deg,val1", cnt, row,col,deg,val1
        print >> outfile, "%s,%s,%0.5f,%0.5f" % (reverse_movie[row],reverse_user[col], val1,deg)


    outfile.close()

def final_cluster_prediction(filename,test_filename,dir_prefix="./cluster.", cosine_sim=False):

    outfile = open(dir_prefix+"test.predictions","w")

    (A,movie_ids,user_ids,m_count,u_count) = read_data(filename)

    reverse_user = inverse_map(user_ids)
    reverse_movie = inverse_map(movie_ids)
    At = A.transpose()
    
    
    trainA = A
    train_m_count = m_count
    train_u_count = u_count
    At = At.tocsr()

    (A,movie_ids,user_ids,m_count,u_count) = read_data(test_filename,movie_ids,user_ids,m_count,u_count,discard=True)
    
    #outfile2 = open(dir_prefix+"test.predictions2","w")

    print ("Total of %d test ratings" % A.nnz)
    (n,m) = A.shape
    cnt=0

    # print_int = min(A.nnz/10,1000)
    # for row in xrange(n):
    #     for row_col_index in xrange(A.indptr[row],A.indptr[row+1]):
    #         col = A.indices[row_col_index]
    #         elt = A.data[row_col_index]
    #         (val1,val2) = predict_with_cluster(col,row,At,graph)
    #         cnt+=1
    #         if (cnt%print_int== 0):
    #             print "cnt,movie,user,val1", cnt, row,col,val1
    #         print >> outfile, "%s,%s,%0.5f" % (reverse_movie[row],reverse_user[col], val1)

    print_int = 100
    for i in xrange(A.nnz)):
        movie = find_index(A.indptr,i)            
        user = A.indices[i]
        (val1,deg) = predict_with_cluster(user,movie,At,trainA,cosine_sim)
        cnt+=1
        if (cnt%print_int == 0):
            print "cnt,movie,user,deg,val1", cnt, row,col,deg,val1
        print >> outfile, "%s,%s,%0.5f,%0.5f" % (reverse_movie[movie],reverse_user[user], val1,deg)
        
    outfile.close()


