\documentclass[11pt]{article}
\usepackage{verbatim}
\usepackage[hyphens]{url}
\usepackage{enumerate}
\setlength{\parindent}{0pt}
\setlength{\parskip}{10pt plus 6pt minus 4pt}

\addtolength{\oddsidemargin}{-.5in}
\addtolength{\evensidemargin}{-.5in}
\addtolength{\textwidth}{+1in}

\title{Progress Report: Non-negative matrix factorization for Who Rated What}
\author{ Brian Huey, Renee Rao }
\date{}


\begin{document}

\maketitle

We are working the Netflix dataset used in the 2007 KDD cup competition which
provides information on characteristics of users of the Netflix video
services who rated movies from the years 1998 to
2006. (http://www.kdd.org/kdd-cup-2007-consumer-recommendations)

We will predict which users rated which movies in 2006. To
test this we will have a provided set of roughly 100000 (user\_id
movie\_id) pairs where the users and movies are drawn from the Netflix
Prize training data set (where none of the pairs were rated in the
training set.) Using this list we will try to predict the probability
that each pair was rated in 2006 (i.e.the probability that user\_id
rated movie\_id in 2006). It is important to note that the actual
rating is irrelevant; we are only interested in whether the movie was
rated by that user sometime in 2006.  

We are provided with a data set of roughly 200 million ratings
for the previous years.


Initial Model: To use non-negative matrix factorization to develop
user features and movie features to then predict ratings for the
Netflix data set. To do this we estimate A, the matrix of movie and
user ids, most of which is considered unknown. We then estimate A by
decomposing it into a user matrix, V and a movie matrix, U based on K
latent factors, such that A ~ U x V = Abar.  Under this model each row
of matrix U is consider a “feature”. A prediction for a user-movie
pair would mean computing the dot product of the user feature vector
and the movie feature vector. Values for V and U are optimized by
taking the product of two randomly initialized matrices and
calculating the squared error of the values of the product matrix from
the known values in A. We then used gradient descent to find the
values of U and V such the squared error would be at a local
minimum. Various correction and normalization steps had to be
undertaken to ensure all entries in U and V are non-negative and
properly scaled. This model was coded in the python script known as
hack.py. Also, one can pre-seed this method with a background
probability, p, of the rating being present by including one extra
dimension that is hardcoded to have a product of p which we set to
baseline probability of any movie being rated in the set but will
eventually be customized to where p can depend on the independent
assumption, that it is proportional to user rating probability times
movie rating probability by particular user) That is, independent
probabilities can be represented by a rank 1 matrix (i.e., a single
number for each movie outer produced with a single number for each
user.) Also, one can use side information to modify background
probabilities based on movie release dates and user first rating
times. This will introduce factors for different timing periods. For
example, a recent user rater should perhaps have higher probability
for recent movies than older movies, so should have a separate number
based on release date. This may already be learned in the other
factors anyway (as might the background as well.)


Data:
      We worked with a small subset of the larger Netflix dataset to train and test our initial algorithm. To do this we randomly selected a subset of 100K observations of the data from before 2005, our training set, and then randomly selected another 100K observations from after 2005, our validation set.  We are not using the 2006 test set until the final report so that we don't falsely overfit to the final output. We also appended extraneous information on movie release dates, outside ratings, and popularity from the Rotten Tomatoes website to be used in later feature engineering for setting p. 


Current Evaluation:
While our RMSE for prediction after 50 iterations on the training set is not great, around .379 and on the test set around .412, we do see that our method is learning something.  For example, on the real ratings our average prediction is around .7, whereas for random unrated movie-user pairs, our prediction is around .4.




One needs to push these numbers apart (perhaps using a logistic function) but the signal is definitely statistically significant for the two kinds of ratings at this preliminary point.




Division of Labor
Brain:
1. Join movie_titles.txt to Rotten Tomatoes info 
2. Set up and organized github
3. Upload of data to sc3
4. Calculate the average number of movies rated over all users in the training set
5. Calculate the average number of ratings over all movies in the training set
6.  Calculate the average number of movies rated for each user in the training set
7.  Calculate the average number of ratings for each movie in the training set
8. Researched K Nearest Neighbor algorithms 




Renee:
1. Subset data into (train) 100K of pre-2005 and 100K (validation) post-2005 data. 
2. Baseline Estimation
3. Wrote Non-Negative Matrix Factorization Model in Python Script
4. Wrote up progress report and Final Proposal. 
















  Tested:
1)  Idea:  using Non-negative factorization to develop
    user features and movie features to then predict
    scores.
       A "feature" is a vector. 
       One prediction algorithm for a rating-movie pair
       is to compute the dot product of the user feature
       vector and the move vector.
       
       Other learning methods could possibly be used.


       Also, one can pre-seed this method with a background
       probability, p, of the rating being present by
       including one extra dimension that is hardcoded
       to have a product of p (where p can depend
       on the independent assumption, is proportional
       to user rating probability times movie rating probability
       by particular user)  That is, independent probabilities
       can be represented by a rank 1 matrix (i.e., a single
       number for each movie outer produced with a single 
       number for each user.)


       Also, one can use side information to modify
       background probabilities based on movie release
       dates and user first rating times.  This will
       introduce factors for different timing periods.
       For example, a recent user rater should perhaps have higher
       probability for recent movies than older movies, so
       should have a separate number based on release date.
       This may already be learned in the other factors
       anyway (as might the background as well.)






2)  Coded NMF implementation so that 


      a) it can be moved to mapreduce....
      b) experiment with various heuristics...


  Algorithm Outline


    1) Our version uses gradient descent on the rmse cost function, with
     a tunable combination of 


        (a) summing rmse over non-zeros.
        (b) summing over random pairs of movie-users to force
            zeros.




       
     2) In enforces positivity on the weights in the matrix
     factor by moving all weights away from zero if they
     get too close to zero, and making negative weights
     positive if the gradient pushes them to negative.


     3) It also normalizes the factors (using a Gramm-Schmitt type
         procedure to make sure all the factors don't simply repeat).
         We again enforce positivity here by staying away from zero.


   Tested:


On generated test cases with known non-negative factorizations, our method seems to converge well.  (Getting very close to the original factorizations.)  Our test cases include both continuous and binary factors. We also tested on samples of the complete data. See Current Evaluation
      below for more details.


   TO DO:
      1)  Maybe think about experimenting with different staying
          away from being negative heuristics.
      2)  Code up the background probability factors.
          Maybe add explicit factors based on movie release dates,
          user first rating time.


      3)  Maybe introduce heuristics to get sparse factors, i.e., factors
          with few non-zero (or actually large) components.  Right
          now "the stay away from negative heuristic" yields very non-sparse
          vectors, since it makes all numbers be strictly greater
          than zero. Perhaps setting small numbers to zero in the final
          prediction phase will improve generalization.  Explicitly
          driving small numbers down and big numbers up in the factor
          should make them more "sparse". Figure out how to add this
          to the gradient descent routine would be interesting.


     4) Code up on map-reduce.  Technically for 200,000,000 ratings,
        it may be better to just use a desktop.  The disk tradeoff may
        be large.   But, it would still be interesting.
          


3) Current evaluation.


   Used 100K samples for preliminary engineering.


   Divided into training pre-2004 and test 2005 ()


   Currently, we do see that our method is learning
   something.  For example, on the real ratings our
   average prediction is around .7, where for random
   (possibly unrated) movie-user pairs, our prediction
   is around .4.


   One needs to push these numbers apart (perhaps using
   a logistic function) but the signal is definitely
   statistically significant for the two kinds of ratings
   at this preliminary point.

\end{document}
